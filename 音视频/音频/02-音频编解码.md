# 常见音视频编码格式

## 1. 常见的音频编码格式

**(1) MP3**

>这种压缩方式的全称叫MPEG Audio Layer3,MP3是利用MPEG Audio Layer 3的技术，将音乐以1:10甚至1:12 的压缩率，压缩成容量较小的file，换句话说，能够在音质丢失很小的情况下把文件压缩到更小的程度。>而且还非常好的保持了原来的音质。
>* 压缩率：10~12倍
>* 优点：压缩比高，适合用于互联网上的传播
>* 缺点： MP3 在 128KBitrate 及以下时，会出现明显的高频丢失

**(2) AAC高级音频编码**

>Advanced Audio Coding。一种专为声音数据设计的文件压缩格式，与MP3不同，它采用了全新的算法进行编码，更加高效，具有更高的“性价比”。利用AAC格式，可使人感觉声音质量没有明显降低aac标志的前提下，更加小巧。AAC属于有损压缩的格式，与时下流行的APE、FLAC等无损格式相比音质存在“本质上”的差距。加之，传输速度更快的USB3.0和16G以上大容量MP3正在加速普及，也使得AAC头上“小巧”的光环不复存在了。
>* 优点：支持多种音频声道组合，提供优质的音质。

**(3) WMA**

>WMA的全称是Windows Media Audio，是微软力推的一种音频格式。WMA格式是以减少数据流量但保持音质的方法来达到更高的压缩率目的，其压缩率一般可以达到1:18，生成的文件大小只有相应MP3文件的一半。
>* 压缩率：10~12倍
>* 缺点：在高比率的渲染能力低下，同音源的一个320KBPS的MP3与比较192KBPS的WMA相比，音质和渲染力很容易分别出是前者较优。因为：
>*   当 Bitrate 小于 128K 时， WMA 最为出色且编码后得到的音频文件很小。
>*   当 Bitrate 大于 128K 时， WMA 音质损失过大。
>* 优点：WMA还可以通过DRM（Digital Rights Management）方案加入防止拷贝，或者加入限制播放时间和播放次数，甚至是播放机器的限制，可有力地防止盗版。

**(4) WAV**

> WAV是录音时用的标准的windows文件格式，文件的扩展名为“.wav”，WAVE文件作为最经典的Windows多媒体音频格式，应用非常广泛。声道有单声道和立体声之分，采样频率一般有11kHz、22kHz和44kHz三种。
> WAVE文件所占容量=（采样频率×采样位数×声道）×时间/8（1字节=8bit）。

**(5) OGG**

>OGG格式的全称应该是OGG Vobis。它是一种新的音频压缩格式，类似于MP3等现有的音乐格式。但有一点不同的是，它是完全免费、开放和没有专利限制的。OGG Vobis有一个很出众的特点，就是支持多声道，
>OGG Vobis在压缩技术上比MP3好，而且它的多声道，免费，开源这些特点，使它很有可能成为一个流行的趋势，这也正是一些MP3播放器对其支持的原因

>可以对所有的声道进行编码，而不是MP3只能编码2个声道。多声道音乐的兴起，给音乐欣赏带来了革命性的变化，尤其在欣赏交响时，会带来更多临场感。这场革命性的变化是MP3无法适应的。在以后的播放技术>不断提高以后，而且人们对音质要求不断提高，Ogg的优势将更加明显。
>* 优点：完全免费。开放没有专利限制。支持多声道

**(6) APE**

>APE的本质，其实它是一种无损压缩音频格式。庞大的WAV音频文件可以通过Monkey”s Audio这个软件进行“瘦身”压缩为APE。有时候它被用做网络音频文件传输，因为被压缩后的APE文件容量要比WAV源文件小一半多，可以节约传输所用的时间。更重要的是，通过Monkey”s Audio解压缩还原以后得到的WAV文件可以做到与压缩前的源文件完全一致,.。所以APE被誉为“无损音频压缩格式”
>* 无损压缩

**各种编码比较**

>* 1.压缩比比较：
>aac>ogg>mp3(wma)>ape>flac>wav（同一音源条件下）
>mp3和wma以192kbps为分界线，192kbps以上mp3好，192kbps以下wma好。
>WMA（10~12），，APE(无损压缩，但庞大的WAV可以瘦身为APE)，，
>ATRAC(1:5)，，MP3(10~12)，，AAC(18~20)，，OGG()，，
>FLAC(1:2)

>* 2.2.音质比较：
>wav=flac=ape>aac>ogg>mp3>wma

>* 3.3.硬件支持比较：
>MP3播放器：mp3>wma>wav>flac>ape aac ogg
>手机：mp3>wma>aac wav>flac ogg>ape

| 种类 | 压缩比   | 支持声道数     | 优点                                                         | 缺点                                                         |
| :--- | :------- | :------------- | :----------------------------------------------------------- | :----------------------------------------------------------- |
| MP3  | 10~12    | 2个声道        | 压缩比高，适合用于互联网上的传播                             | 在 128KBitrate 及以下时，会出现明显的高频丢失                |
| WMA  | 10~12    |                | 当 Bitrate 小于 128K 时， WMA 最为出色且编码后得到的音频文件很小。 | 当 Bitrate 大于 128K 时， WMA 音质损失过大。                 |
| OGG  |          | 支持多声道     | OGG Vobis在压缩技术上比MP3好，而且它的多声道                 |                                                              |
| AAC  | 18~20    | 支持多声道     | 支持多种音频声道组合，提供优质的音质                         | 与时下流行的APE、FLAC等无损格式相比音质存在“本质上”的差距。加之，传输速度更快的USB3.0和16G以上大容量MP3正在加速普及，也使得AAC头上“小巧”的光环不复存在了。 |
| APE  | 无损压缩 |                | 用做网络音频文件传输，因为被压缩后的APE文件容量要比WAV源文件小一半多，可以节约传输所用的时间。 |                                                              |
| FLAC | 2        |                |                                                              |                                                              |
| WAV  | 无损压缩 | 单声道和立体声 | WAVE文件作为最经典的Windows多媒体音频格式                    |                                                              |

## 2 部分编解码原理

### 2.1 OPUS

> 原文链接：https://blog.csdn.net/qq_42233059/article/details/135004677

OPUS（Opus交互式音频编解码器）是一种开放、免版权的音频编解码格式，它旨在提供低延迟、高音质的音频传输和存储解决方案。OPUS编解码器的核心原理：混合了多种音频编解码技术，包括线性预测编码（LPC）、MDCT变换、矢量量化、熵编码等。它利用语音信号的特性进行声学建模和数据压缩，以实现高效的音频编解码。

#### OPUS编解码步骤

- 预处理：原始音频信号经过预处理步骤，包括滤波、重采样、音频增益调整等，以适应编码器的要求。

- 分帧：音频信号被分成较短的时间片段，通常为20毫秒至60毫秒。每个时间片段称为一个帧，用于后续处理和编码。

- 特征提取：对每个帧进行特征提取，常见的特征包括短时频谱、倒谱系数、线性预测系数等，用于声学建模和编码。

- 编码：采用多种编码技术对提取的特征进行编码。OPUS使用了混合编码的方法，包括MDCT变换、矢量量化、残差编码等。编码过程中，根据音频信号的特性选择合适的编码算法和参数。

  OPUS支持多种编码模式，包括VOIP模式（适用于实时通信）、音乐模式（适用于音乐和高保真音频）、语音模式（适用于语音和语音识别）等。每种模式都针对不同的音频类型和应用场景进行了优化，以提供最佳的音频质量和压缩效率。

  OPUS提供了多种码率控制模式，包括恒定比特率（CBR）、可变比特率（VBR）和恒定质量（CVBR）。恒定比特率模式固定每个帧的比特率，适用于网络带宽固定或有严格比特率限制的场景；可变比特率模式根据音频内容动态调整比特率，以提供更高的压缩效率；恒定质量模式通过自适应比特率控制，以保持一致的音频质量。

  编码器实现：OPUS编码器是由一组开源库和工具组成，可供开发人员使用。其中包括libopus库，它是一个用于编码和解码OPUS音频的C语言库。libopus提供了简单的API，使开发人员可以轻松地集成OPUS编解码功能到他们的应用程序中。

  语音活动检测（VAD）：OPUS编码器集成了语音活动检测（VAD）功能。VAD可以检测输入音频中的语音活动和非语音活动部分，并相应地调整编码参数。这有助于减少非语音活动部分的编码量，提高压缩效率。

- 熵编码：对编码后的数据进行熵编码，以减少数据的表示所需的比特数。OPUS使用了多种熵编码技术，如算术编码、霍夫曼编码等。

- 打包：将编码和熵编码后的数据打包成音频帧，包括音频数据、控制信息、帧同步标志等。打包后的数据可以进行传输或存储。

  音频流封装：OPUS编码的音频可以以不同的封装格式进行存储或传输。常见的封装格式包括Ogg封装格式（.ogg文件）、Matroska封装格式（.mkv文件）和WebM封装格式（.webm文件）。这些封装格式可以容纳OPUS编码的音频数据以及其他相关信息，如元数据、时间戳和同步信息。

  比特率范围：OPUS支持的比特率范围很广，从非常低的比特率（例如6 kbps）到非常高的比特率（例如512 kbps）。这使得OPUS适用于不同的应用需求，从低带宽网络环境到高质量音频存储。

  混流和分流：OPUS编码器还支持多个音频流的混流和分流。这意味着可以将多个音频流合并成一个OPUS流，或者从一个OPUS流中分离出多个音频流。这种能力对于多路音频传输和处理非常有用，例如音频会议中的多个参与者。

- 解码：接收端或解码端接收到打包的数据后，进行解码操作。解码过程与编码过程相反，包括解析数据帧、熵解码、解码特征、合成音频等。

- 合成：解码后的特征经过合成处理，包括逆变换、重叠、相加等，以还原原始的音频信号。

- 后处理：解码后的音频信号进行后处理，包括滤波、音频增益调整、重采样等，以适应最终的播放设备或应用需求。

#### OPUS编码特性

OPUS被设计为低延迟的音频编解码器，**适用于实时通信等对延迟要求较高的应用**。OPUS的延迟主要由帧长和编码算法决定，较短的帧长可以减少延迟，但会导致较高的比特率。在VOIP模式下，OPUS可以实现非常低的端到端延迟，通常在20毫秒到60毫秒之间。

- 容错性：OPUS具有一定的容错性，可以在网络丢包或丢失部分数据的情况下仍能提供较好的音频质量。OPUS使用了纠错编码和前向纠错技术，通过重采样、插值和隐藏丢失数据等方法来恢复丢失的音频数据。

- 平台支持：OPUS是一种跨平台的音频编解码格式，支持在多种操作系统和硬件平台上使用。它具有广泛的应用支持，包括桌面应用、移动应用、浏览器等，可以在不同设备和平台上进行音频编解码和传输。

- 音频质量：OPUS以其出色的音频质量而闻名。它具有广泛的音频频带宽范围（从超低频到高频），能够适应不同类型的音频内容，并提供高保真度的音频重现。

- 低延迟：OPUS被设计为低延迟的音频编解码器，适用于实时通信应用。它可以在保持较低延迟的同时提供高质量的音频传输。

- 高效的压缩：OPUS具有出色的压缩性能，可以在较低的比特率下提供高质量的音频。它采用了多种音频编码技术和自适应比特率控制，以提供最佳的音频编解码效率。

- 支持多通道音频：OPUS支持多通道音频编解码，包括立体声、5.1声道和7.1声道等。这使得OPUS适用于多通道音频应用，如音频录制、音频处理和游戏音频。

- 不同应用场景的配置参数：OPUS提供了一系列的配置参数，允许用户根据应用需求进行定制。这些参数包括帧大小、比特率、预测算法和复杂度等。通过调整这些参数，可以在音频质量、延迟和压缩率之间进行平衡。

总体而言，OPUS是一种灵活、高效和适用于多种应用场景的音频编解码格式。OPUS的编解码过程可以根据实际需求进行参数配置，以平衡音频质量、延迟和压缩率，它能够提供低延迟、高音质的音频传输和存储解决方案，广泛用于语音通信、音频会议、流媒体、语音识别和语音交互等领域。



#### OPUS为何能抗弱网

Opus编码之所以能够在弱网环境下表现出良好的抗丢包能力，主要有以下几个原因：

1. **鲁棒性设计**：Opus编码器在设计时就考虑到了网络的不稳定性。它内置了多种机制来处理网络中的丢包问题，如数据包丢失隐藏（PLC）技术。当网络中的数据包丢失时，Opus能够利用已接收的数据包来预测和重建丢失的数据，从而保持音频的连续性和可听性。
2. **可变比特率（VBR）和帧大小**：Opus支持可变比特率和帧大小，这意味着它可以根据网络条件实时调整编码参数。在弱网环境下，Opus可以降低比特率并减小帧大小，以减少数据包的大小和数量，从而降低网络拥塞和丢包的风险。
3. **高效的编码算法**：Opus采用了先进的编码算法，能够在保证音频质量的同时，尽可能减小编码后的数据量。这使得在相同的网络带宽下，Opus能够传输更多的音频数据，从而提高了音频的流畅性和清晰度。
4. **灵活的带宽分配**：Opus编码器能够动态地调整音频带宽，以适应网络带宽的变化。在弱网环境下，Opus可以减少音频带宽的使用，以确保音频数据的稳定传输。
5. **支持前向纠错（FEC）**：虽然Opus本身并不直接支持前向纠错，但它可以与其他支持FEC的传输协议（如RTP/RTCP）结合使用。FEC能够在传输过程中为数据包添加冗余信息，以便在接收端检测到丢包时能够恢复部分丢失的数据。这种结合使用的方式可以进一步提高Opus在弱网环境下的抗丢包能力。

综上所述，Opus编码之所以能够抗弱网，主要是因为其具备鲁棒性设计、可变比特率和帧大小、高效的编码算法、灵活的带宽分配以及支持前向纠错等特性。这些特性使得Opus能够在弱网环境下保持音频的连续性和可听性，为用户提供更好的音频体验。

**WebRTC针对带内FEC的实现**

> https://blog.jianchihu.net/webrtc-research-audio-inband-fec.html

带内FEC整个闭环处理比较简单：

- 从Receiver Report中获取丢包率
- 平滑处理丢包率
- 平滑后的丢包率反馈给Opus编码器

`AudioEncoderOpusImpl::OnReceivedUplinkPacketLossFraction`负责相关处理。
**接收通过RTCP反馈的丢包率，传给Opus编码器。**

```cpp
void AudioEncoderOpusImpl::OnReceivedUplinkPacketLossFraction(
    float uplink_packet_loss_fraction) {
  if (audio_network_adaptor_) {
    audio_network_adaptor_->SetUplinkPacketLossFraction(
        uplink_packet_loss_fraction);
    ApplyAudioNetworkAdaptor();
  }
  // 对丢包率进行平滑处理
  packet_loss_fraction_smoother_->AddSample(uplink_packet_loss_fraction);
  float average_fraction_loss = packet_loss_fraction_smoother_->GetAverage();
  SetProjectedPacketLossRate(average_fraction_loss);
}
 
void AudioEncoderOpusImpl::SetProjectedPacketLossRate(float fraction) {
  // 允许的最大丢包率为20%
  fraction = std::min(std::max(fraction, 0.0f), kMaxPacketLossFraction);
  if (packet_loss_rate_ != fraction) {
    packet_loss_rate_ = fraction;
    // 传递丢包率到Opus编码器
    RTC_CHECK_EQ(
        0, WebRtcOpus_SetPacketLossRate(
               inst_, static_cast<int32_t>(packet_loss_rate_ * 100 + .5)));
  }
}
```



#### libopus使用

> https://blog.csdn.net/sinat_27720649/article/details/126530085



## 其他概念

###  前向纠错（FEC）

它的基本原理是在发送数据之前，对数据进行冗余编码，使得数据在传输过程中即使出现了错误，也能够通过冗余信息进行错误检测和纠正，从而保证数据的完整性和准确性。

FEC（前向纠错）机制的原理是在数据传输过程中，通过在发送端添加冗余数据（即纠错码）来检测和纠正可能发生的传输错误。以下是FEC机制原理的详细解释：

1. 编码：在发送端，原始数据首先被分为多个小块（也称为数据包）。然后，根据特定的编码规则（如循环冗余校验（CRC）、里德-所罗门码（Reed-Solomon codes）、汉明码（Hamming codes）等），将这些小块与冗余数据（纠错码）结合，生成一个包含原始数据和纠错码的数据包。这个数据包随后被发送到接收端。
2. 传输：编码后的数据包通过网络或通信信道发送到接收端。在传输过程中，可能会由于各种原因（如网络拥塞、干扰、噪声等）导致数据包中的某些位发生变化，从而产生错误。
3. 解码与纠错：在接收端，接收到的数据包首先经过解码过程。解码器使用与发送端相同的纠错码算法来分析接收到的数据包。如果检测到错误，解码器会尝试使用冗余数据（即纠错码）来纠正这些错误，恢复出原始数据。具体来说，解码器会分析数据包中的纠错码，确定错误的位置和类型，然后使用纠错码来修正这些错误。如果错误超出了纠错能力范围，则可能无法完全恢复数据。

通过这种方式，FEC机制可以在数据传输过程中检测和纠正错误，从而提高数据传输的可靠性和稳定性。它不需要在检测到错误后重新发送数据，而是可以在接收端直接纠正错误，从而减少了传输延迟和带宽占用。

### 数据包丢失隐藏技术（PLC）

数据包丢失隐藏技术（Packet Loss Concealment，PLC）是一种在通信过程中，特别是在实时语音或视频传输中，当遇到数据包丢失时用于隐藏或补偿丢失数据的技术。

在实时语音通信中，如果在接收端存在无法通过前向纠错等算法恢复的丢失帧，就需要对语音信息进行处理。丢包隐藏技术通常利用听觉感知模型中的人耳的听觉掩蔽效应，对丢失的语音波形进行补偿，使得人耳听起来感觉没有很大的影响。

具体来说，丢包隐藏技术可以通过以下方式实现：

1. **零插入**：当检测到数据包丢失时，将丢失的语音帧替换为零，即静音处理。
2. **波形替代**：通过重复已经接收到的语音的一部分来重建丢失的语音帧。
3. **参数插值**：对于基于参数的语音编码，可以利用已接收到的语音帧的参数来插值或预测丢失帧的参数。

丢包隐藏技术并不真正恢复丢失的数据，而是通过模拟或预测来弥补丢帧带来的影响。因此，它通常适用于丢包率不高的情况，如经过其他丢包恢复技术处理后剩下的少量无法恢复的包。

在实时通信中，丢包隐藏技术对于保持音频和视频流的连续性和可听性至关重要。特别是在无线信道等恶劣的传输环境下，丢包隐藏技术能够显著提高通信质量。





